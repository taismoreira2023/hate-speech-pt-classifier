{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq3B_t1-n7to"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from huggingface_hub import login\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from datasets import concatenate_datasets\n",
        "import unidecode\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk import tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNAyZ2ks1_Xu"
      },
      "outputs": [],
      "source": [
        "irrelevant_words = nltk.corpus.stopwords.words('portuguese')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox8jwdAw2D0m"
      },
      "outputs": [],
      "source": [
        "def stopWordsUnidecode(example):\n",
        "\n",
        "    processed_sentence = []\n",
        "    stopWords_unidecode = [unidecode.unidecode(phrase) for phrase in irrelevant_words]\n",
        "\n",
        "    text = example['text']\n",
        "    unidecode_text = unidecode.unidecode(text)\n",
        "    word_punct_tokenizer = tokenize.WordPunctTokenizer()\n",
        "    text_token = word_punct_tokenizer.tokenize(unidecode_text)\n",
        "    new_word = [word for word in text_token if word.isalpha() and word not in stopWords_unidecode]\n",
        "    processed_sentence.append(' '.join(new_word))\n",
        "\n",
        "    example['processing_Unidecode'] = ' '.join(processed_sentence)\n",
        "\n",
        "    return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXmUZkrH2DxI"
      },
      "outputs": [],
      "source": [
        "login(token='YOUR_HUGGINGFACE_TOKEN')\n",
        "\n",
        "dataset = load_dataset(\"manueltonneau/portuguese-hate-speech-superset\",token=True)\n",
        "\n",
        "dataset = dataset['train']\n",
        "dataset = dataset.remove_columns(['target', 'nb_annotators','dataset','source'])\n",
        "\n",
        "new_dataset = load_dataset('franciellevargas/HateBR')\n",
        "\n",
        "new_dataset = new_dataset['train']\n",
        "dt = new_dataset.remove_columns(['id', 'anotator1', 'anotator2', 'anotator3', 'links_post', 'account_post'])\n",
        "hate = dt.filter(lambda x: x['label_final'] == 1)\n",
        "hate = hate.rename_columns({'comentario': 'text', 'label_final': 'labels'})\n",
        "dataset = concatenate_datasets([hate,dataset])\n",
        "dataset = dataset.map(stopWordsUnidecode)\n",
        "dataset['text']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1IyyXRu2Dt7"
      },
      "outputs": [],
      "source": [
        "dataset['processing_Unidecode']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTHXBPvn2DrD"
      },
      "outputs": [],
      "source": [
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "model_name = \"ruanchaves/bert-large-portuguese-cased-hatebr\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Treinando no dispositivo: {device}\")\n",
        "print(torch.cuda.device_count())\n",
        "print(\"Local rank:\", os.environ.get(\"LOCAL_RANK\"))\n",
        "print(\"Current device:\", torch.cuda.current_device())\n",
        "print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70WGwBAF2Dnp"
      },
      "outputs": [],
      "source": [
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"processing_Unidecode\"], padding=\"max_length\", truncation=True, max_length=70)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_test_split = tokenized_dataset.train_test_split(test_size=0.2 )\n",
        "train_dataset = train_test_split[\"train\"]\n",
        "eveal_dataset = train_test_split[\"test\"]\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "f1 = evaluate.load(\"f1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPwnjgcd2Dkn"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
        "    f1_macro = f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
        "    return {\"accuracy\": acc, \"f1\": f1_macro}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4-myh362DY7"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results1/classificador_odio.model\",\n",
        "    per_device_train_batch_size=8,\n",
        "    gradient_accumulation_steps= 8,\n",
        "    fp16= True,\n",
        "    num_train_epochs=3,\n",
        "    logging_dir=\"./logs\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "class_weights = torch.tensor([1.0, 1 0.0])\n",
        "loss_fn = CrossEntropyLoss(weight=class_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPlPPrX12VeV"
      },
      "outputs": [],
      "source": [
        "class CustomLossTrainer(Trainer):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        self.class_weight = kwargs.pop(\"class_weight\", None)\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # class_weight existe, aplica no CrossEntropyLoss, senão usa o default.\n",
        "        if self.class_weight is not None:\n",
        "          loss_fct = CrossEntropyLoss(weight=self.class_weight.to(labels.device))\n",
        "        else:\n",
        "          loss_fct = CrossEntropyLoss()\n",
        "\n",
        "        loss = loss_fct(logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QE3Gfx0r2evA"
      },
      "outputs": [],
      "source": [
        "trainer = CustomLossTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eveal_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    class_weight=class_weights,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgkkvvZj2epN"
      },
      "outputs": [],
      "source": [
        "example = \"Esse trabalho é uma ótimo arrasou!\"\n",
        "local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n",
        "device = torch.device(f\"cuda:{local_rank}\")\n",
        "model.to(device)\n",
        "inputs = tokenizer(example, return_tensors=\"pt\")\n",
        "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "pred = torch.argmax(outputs.logits, dim=-1).item()\n",
        "\n",
        "# Mostra o resultado\n",
        "print(f\"Frase: {example}\")\n",
        "print(f\"Classe prevista: {pred}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
