# ğŸ§  Portuguese Hate Speech Detector

Modelo de classificaÃ§Ã£o de discurso de Ã³dio em portuguÃªs, desenvolvido com **Transformers (Hugging Face)**.  
Este projeto realiza **fine-tuning de um modelo BERT** sobre mÃºltiplos datasets de linguagem ofensiva, com o objetivo de detectar comentÃ¡rios de Ã³dio e toxicidade em texto.

---

## ğŸš€ VisÃ£o Geral

O **Portuguese Hate Speech Detector** combina dois datasets pÃºblicos:
- [`manueltonneau/portuguese-hate-speech-superset`](https://huggingface.co/datasets/manueltonneau/portuguese-hate-speech-superset)
- [`franciellevargas/HateBR`](https://huggingface.co/datasets/franciellevargas/HateBR)

O modelo base Ã© o **[`ruanchaves/bert-large-portuguese-cased-hatebr`](https://huggingface.co/ruanchaves/bert-large-portuguese-cased-hatebr)**, ajustado com pesos de classe para lidar com desbalanceamento de dados.  
O objetivo Ã© detectar se um texto contÃ©m **discurso de Ã³dio (classe 1)** ou **linguagem neutra (classe 0)**.

---

## âš™ï¸ Tecnologias Utilizadas

- ğŸ§© [Hugging Face Transformers](https://huggingface.co/transformers)
- ğŸ“š [Datasets](https://huggingface.co/docs/datasets)
- ğŸ§® [PyTorch](https://pytorch.org/)
- ğŸ“ˆ [Evaluate (Hugging Face)](https://huggingface.co/docs/evaluate)
- ğŸ§° [Trainer API](https://huggingface.co/docs/transformers/main_classes/trainer)
- ğŸ’¾ GPU com CUDA (opcional, mas recomendÃ¡vel)

## ğŸ§  Treinamento

O script realiza:
1. Carregamento e limpeza dos datasets.  
2. TokenizaÃ§Ã£o com `AutoTokenizer`.  
3. ConcatenaÃ§Ã£o de mÃºltiplos conjuntos anotados.  
4. AplicaÃ§Ã£o de pesos de classe para lidar com desbalanceamento.  
5. Treinamento e avaliaÃ§Ã£o usando a API do `Trainer`.

### ParÃ¢metros principais:
- `batch_size = 8`
- `gradient_accumulation_steps = 8`
- `epochs = 3`
- `fp16 = True` (treinamento em meia precisÃ£o)
- `metric_for_best_model = "f1"`

---

## ğŸ“Š MÃ©tricas

As mÃ©tricas utilizadas para avaliaÃ§Ã£o sÃ£o:
- **Accuracy**  
- **F1 (macro)** â€“ mÃ©trica principal usada para salvar o melhor modelo.

Exemplo de saÃ­da (simulada):

| Ã‰poca | Accuracy | F1 (macro) |
|--------|-------------|--------------|
| 1 | 0.804815 | 0.725156 |
| 2 | 0.838523 | 0.753326 |
| 3 | 0.852220 | 0.761679 âœ… (melhor modelo) |


## ğŸ’¬ Exemplo de InferÃªncia

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

model_name = "results1/classificador_odio.model/checkpoint-1755"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

example = "Esse trabalho Ã© uma porcaria inÃºtil"
inputs = tokenizer(example, return_tensors="pt")
with torch.no_grad():
    outputs = model(**inputs)
pred = torch.argmax(outputs.logits, dim=-1).item()

print(f"Texto: {example}")
print(f"Classe prevista: {pred}")
# 0 = neutro, 1 = discurso de Ã³dio
```

ğŸ§¾ LicenÃ§a
Este projeto Ã© distribuÃ­do sob a licenÃ§a MIT.
VocÃª Ã© livre para usar, modificar e distribuir, desde que mantenha os crÃ©ditos.

