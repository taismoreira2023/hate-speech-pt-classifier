# üß† Portuguese Hate Speech Detector

Modelo de classifica√ß√£o de discurso de √≥dio em portugu√™s, desenvolvido com **Transformers (Hugging Face)**.  
Este projeto realiza **fine-tuning de um modelo BERT** sobre m√∫ltiplos datasets de linguagem ofensiva, com o objetivo de detectar coment√°rios de √≥dio e toxicidade em texto.

---

## üöÄ Vis√£o Geral

O **Portuguese Hate Speech Detector** combina dois datasets p√∫blicos:
- [`manueltonneau/portuguese-hate-speech-superset`](https://huggingface.co/datasets/manueltonneau/portuguese-hate-speech-superset)
- [`franciellevargas/HateBR`](https://huggingface.co/datasets/franciellevargas/HateBR)

O modelo base √© o **[`ruanchaves/bert-large-portuguese-cased-hatebr`](https://huggingface.co/ruanchaves/bert-large-portuguese-cased-hatebr)**, ajustado com pesos de classe para lidar com desbalanceamento de dados.  
O objetivo √© detectar se um texto cont√©m **discurso de √≥dio (classe 1)** ou **linguagem neutra (classe 0)**.

---

## **Clonar o reposit√≥rio**

```bash
git clone https://github.com/taismoreira2023/hate-speech-pt-classifier.git
cd hate-speech-pt-classifier
```
## **Criar o ambiente virtual**

### **Windows (PowerShell)**

```powershell
.\venv.ps1
```

### **Linux / macOS**

```bash
./venv.sh
```

---

## ‚öôÔ∏è Tecnologias Utilizadas

- üß© [Hugging Face Transformers](https://huggingface.co/transformers)
- üìö [Datasets](https://huggingface.co/docs/datasets)
- üßÆ [PyTorch](https://pytorch.org/)
- üìà [Evaluate (Hugging Face)](https://huggingface.co/docs/evaluate)
- üß∞ [Trainer API](https://huggingface.co/docs/transformers/main_classes/trainer)
- üíæ GPU com CUDA (opcional, mas recomend√°vel)

---
## üß† Treinamento
Para executar o treinamento completo:

```bash
python script/classificacao_discurso_odio.py
```

O script realiza:
1. Carregamento e limpeza dos datasets.  
2. Tokeniza√ß√£o com `AutoTokenizer`.  
3. Concatena√ß√£o de m√∫ltiplos conjuntos anotados.  
4. Aplica√ß√£o de pesos de classe para lidar com desbalanceamento.  
5. Treinamento e avalia√ß√£o usando a API do `Trainer`.

### Par√¢metros principais:
- `batch_size = 8`
- `gradient_accumulation_steps = 8`
- `epochs = 3`
- `fp16 = True` (treinamento em meia precis√£o)
- `metric_for_best_model = "f1"`

---

## üìä M√©tricas

As m√©tricas utilizadas para avalia√ß√£o s√£o:
- **Accuracy**  
- **F1 (macro)** ‚Äì m√©trica principal usada para salvar o melhor modelo.

Exemplo de sa√≠da (simulada):

| √âpoca | Accuracy | F1 (macro) |
|--------|-------------|--------------|
| 1 | 0.804815 | 0.725156 |
| 2 | 0.838523 | 0.753326 |
| 3 | 0.852220 | 0.761679 ‚úÖ (melhor modelo) |

---
##**Executar a infer√™ncia (classifica√ß√£o de texto)**

Criado arquivo `predict.py` com o conte√∫do:

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

model_name = "results1/classificador_odio.model/checkpoint-1755"  # ajuste para o seu caminho

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

example = "Esse trabalho √© uma porcaria in√∫til"
inputs = tokenizer(example, return_tensors="pt")

with torch.no_grad():
    outputs = model(**inputs)

pred = torch.argmax(outputs.logits, dim=-1).item()

print(f"Texto: {example}")
print(f"Classe prevista: {pred}")
# 0 = neutro, 1 = discurso de √≥dio
```

Execute:

```bash
python predict.py
```

---
üßæ Licen√ßa
Este projeto √© distribu√≠do sob a licen√ßa MIT.
Voc√™ √© livre para usar, modificar e distribuir, desde que mantenha os cr√©ditos.
